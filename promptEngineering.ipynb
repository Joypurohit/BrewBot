{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSTALLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.63.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\chinmay purohit\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: load_dotenv in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.1.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from load_dotenv) (1.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install openai\n",
    "%pip install load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==2.2.3 in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas==2.2.3) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chinmay purohit\\appdata\\roaming\\python\\python313\\site-packages (from pandas==2.2.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas==2.2.3) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas==2.2.3) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chinmay purohit\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas==2.2.3) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas==2.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\chinmay purohit\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.2.3)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 3.7/11.1 MB 20.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.6/11.1 MB 16.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.2/11.1 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 14.0 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.2-cp313-cp313-win_amd64.whl (41.0 MB)\n",
      "   ---------------------------------------- 0.0/41.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.1/41.0 MB 19.0 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 6.3/41.0 MB 14.9 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 9.2/41.0 MB 14.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 12.1/41.0 MB 13.9 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.7/41.0 MB 13.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 17.6/41.0 MB 13.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 20.2/41.0 MB 13.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 23.1/41.0 MB 13.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 25.7/41.0 MB 13.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 28.6/41.0 MB 13.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 31.5/41.0 MB 13.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 34.1/41.0 MB 13.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.0/41.0 MB 13.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.6/41.0 MB 13.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.0/41.0 MB 12.9 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function dotenv.main.load_dotenv(dotenv_path: Union[str, ForwardRef('os.PathLike[str]'), NoneType] = None, stream: Optional[IO[str]] = None, verbose: bool = False, override: bool = False, interpolate: bool = True, encoding: Optional[str] = 'utf-8') -> bool>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import json\n",
    "load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM FUNCTION TO GET CHATBOT RESPONSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChatbotResponse(client,messages,model_name,temperature,maxTokens):\n",
    "    messages_list = []\n",
    "    for message in messages:\n",
    "        messages_list.append({\"role\": message['role'], \"content\": message['content']})\n",
    "    response = client.chatCompletion(\n",
    "        model=model_name,\n",
    "        messages=messages_list,\n",
    "        temperature=temperature,\n",
    "        max_tokens=maxTokens,\n",
    "        top_p=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages =[{ \"role\": \"system\", \"content\": \"You are a helpful assistant.\" }, { \"role\": \"user\", \"content\": \"SUggest me a healthy iced coffee?\" }]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPT ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERATION OF STRUCTURED OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =\"\"\"  \n",
    "\n",
    "You are a helpful assistant. You will only give the response in a structured format as given below and will not provide any other information.\n",
    "Please dont write anything other than the json object. The expected format is as follows:\n",
    "\n",
    "[\n",
    "    {\n",
    "        \"name\":\"This will be the name of the coffee\",\n",
    "        \"ingredients\":\"These will be the ingredients of the coffee\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "messages = [{\"role\":\"system\",\"content\":prompt}]\n",
    "messages.append({\"role\":\"user\",\"content\":\"Suggest me a healthy coffee and also mention its ingredients on why its healthy?\"})\n",
    "\n",
    "# use json.loads to load the json response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INPUT STRUCTURING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_input = \"\"\" \n",
    "\n",
    "From the following coffee options given below , please rank them in order of their healthiness. The options are as follows:\n",
    "'''\n",
    "1. Black Coffee\n",
    "2. Latte\n",
    "3. Cappuccino\n",
    "4. Fraappuccino\n",
    "5. Chocolate Mocha\n",
    "6. Hot Chocolate\n",
    "7. Iced Coffee\n",
    "8. Espresso\n",
    "9. Macchiato\n",
    "10. Vanilla Caramel Frappuccino\n",
    "'''\n",
    "\n",
    "\"\"\"\n",
    "messages = [{\"role\":\"system\",\"content\":prompt}]\n",
    "messages.append({\"role\":\"user\",\"content\":structured_input})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHAIN OF THOUGHT - Giving the model time to think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example, the core idea of this is to provide the steps attribute which will guide the llm to generate the response\n",
    "\n",
    "prompt =\"\"\"  \n",
    "\n",
    "You are a helpful assistant. Compute the value of 2*6+9/2. You will only give the response in a structured format as given below and will not provide any other information.\n",
    "Please dont write anything other than the json object. The expected format is as follows:\n",
    "\n",
    "[\n",
    "    {\n",
    "        \"steps\": \"You will solve the equation bit by bit and will follow the BODMAS rule to compute the final equation. It states that the\n",
    "        precedence of the operators is as follows: Brackets, Orders, Division and Multiplication, Addition and Subtraction. So follow this \n",
    "        to compute the final result.\",\n",
    "        \"result\": \"The result of the expression\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_health_description = \"\"\"\n",
    "\n",
    "If you’re looking for antioxidants, stick with hot-brewed coffee. It has more because it takes a certain amount of heat to extract antioxidants from the bean. But if it’s caffeine you’re after, cold brew will give you a stronger jolt. Cold brew is also lower in acid, and a better choice if you have acid reflux.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_prompt = f\"\"\"\n",
    "    {coffee_health_description}\n",
    "    I want to drink coffee to detoxify my digestive system with antioxidants. Can you suggest me if i should drink hot brewed coffee or cold brew coffee?\n",
    "\n",
    " \"\"\"\n",
    "\n",
    "messages = [{\"role\":\"system\",\"content\":prompt}]\n",
    "messages.append({\"role\":\"user\",\"content\":new_user_prompt})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting content from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "capaccuino_desc = \"\"\"Cappuccino (/ˌkæpʊˈtʃiːnoʊ/ ⓘ, Italian: [kapputˈtʃiːno]; from German Kapuziner)[1] is an espresso-based coffee drink that is traditionally prepared with steamed milk including a layer of milk foam.[2]\n",
    "\n",
    "Variations of the drink involve the use of cream instead of milk, using non-dairy milk substitutes and flavoring with cocoa powder (in Europe and Australasia) or cinnamon (in the United States and South Korea).[3][4] It is typically smaller in volume than that of a caffè latte, and topped with a thick layer of foam rather than being made with microfoam.[5]\n",
    "\n",
    "The name comes from the Capuchin friars, referring to the color of their habits,[6] and in this context, referring to the color of the beverage when milk is added in small portion to dark, brewed coffee[7] (today mostly espresso). The physical appearance of a modern cappuccino with espresso crema and steamed milk is a result of a long evolution of the drink.\n",
    "\n",
    "The Viennese bestowed the name Kapuziner, possibly in the 18th century, on an early version that included whipped cream and spices. Later, the Kapuziner was introduced in northern Italy during the period of Austrian domination and Italians started to use it for the beverage as well the friar dress.[8] It is sometimes said to have been served in the coffeehouses of Trieste and other Italian areas of the Austro-Hungarian Empire in the early 20th century, spreading throughout the Kingdom of Italy after World War I. However, the existence in central Italy of a coffee drink mixed with milk named cappuccino is already documented in the 19th century.[9]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "frapuccino_desc = \"\"\"\n",
    "Frappuccino is a line of blended iced coffee drinks sold by Starbucks.[2] It may consist of coffee or crème base, blended with ice and ingredients such as flavored syrups and usually topped with whipped cream and or spices. It may also include blended Starbucks refreshers. Frappuccinos are also sold as bottled coffee beverages in grocery stores, convenience stores and from vending machines.\n",
    "Frappuccino is a portmanteau of \"frappé\" (pronounced /fræp/ and also spelled without the accent)—the New England name for a thick milkshake with ice cream, derived from the French word lait frappé (beaten milk)[3][4]—and cappuccino, an espresso coffee with frothed milk.[3][1]\n",
    "\n",
    "The Frappuccino was originally developed, trademarked, and sold by George Howell's Eastern Massachusetts coffee shop chain the Coffee Connection, and created and named by his marketing director, Andrew Frank.[3] When Starbucks purchased the Coffee Connection in 1994, they gained the rights to use, make, market, and sell the Frappuccino drink.[3] The drink, with a different recipe, was introduced under the Starbucks name in 1995. In 2012, Starbucks had annual Frappuccino sales of over $2 billion.[3]\n",
    "The recipe is derived from a fusion of various cold drinks, including the \"coffee frap\" (similar to iced coffee)[dubious – discuss] and the \"frappe\" (blended ice cream, syrup, and milk), with the Italian cappuccino.[1][5][6][7] The recipe consists of an instant coffee mix, ice, an emulsifying agent such as xanthan gum,[8] and other additives such as milk, sugar, flavored syrups, and whipped cream.[9]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [capaccuino_desc,frapuccino_desc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Can you give the history of cappuccino?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_client = OpenAI(api_key=os.getenv(\"RUNPOD_TOKEN\"),base_url=os.getenv(\"RUNPOD_EMBEDDING_URL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(client,model_name,input_data):\n",
    "    response = client.embeddings.create(\n",
    "        model=model_name,\n",
    "        input=input_data\n",
    "    )\n",
    "    embeddings=[]\n",
    "    for obj in response:\n",
    "        embeddings.append(obj.embedding)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_embedding = get_embedding(embedding_client,\"bge-small-en-v1.5\",user_prompt)\n",
    "data_embeddings = [get_embedding(embedding_client,\"bge-small-en-v1.5\",data[0]),get_embedding(embedding_client,\"bge-small-en-v1.5\",data[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_similarity = cosine_similarity([user_prompt_embedding],data_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_chosen = data_similarity.argmax()\n",
    "print(data[index_chosen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_RAG = f\"\"\"\n",
    "    {data[index_chosen]}\n",
    "    Can you give history of cappuccino?\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\":\"system\",\"content\":prompt}]\n",
    "messages.append({\"role\":\"user\",\"content\":user_prompt_RAG})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
